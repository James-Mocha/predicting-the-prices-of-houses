import numpy as np
import numpy.random as rnd

# Read the data
# Download "data.csv" from the course website
data = np.genfromtxt('data.csv', delimiter=',', skip_header=1)

# Display the *shape* of the data matrix
print(data.shape)


# Please leave these print statements, to help your TAs grade quickly.
print('\n\nQuestion 1')
print('----------')

print('\nQuestion 1(a):') # Please leave print statements like these

# print(...) # TODO: Only print your answer.

print(data[0:10,0])


print('\nQuestion 1(b):')

# Include your response in your writeup

print(data[0:10,1])

print('\nQuestion 1(c):')
print("Part(a) is the NO. which mean is the number of house ")
print("Part(b) is the transaction date of the house")


print('\nQuestion 1(d):')
# data = ... # TODO
data = data[:,1:]
print(data.shape)


test = data[data[:, 0] > 2013.417]
print(test.shape)

print('\nQuestion 1(e):')
print("Data from too long ago are of little significance for current assessments")
# Include your response in your writeup

print('\nQuestion 1(f):')

train_valid = np.asarray(data[data[:, 0] <= 2013.417])

print(test.shape)
print(train_valid.shape)

print('\nQuestion 1(g):')

# Below array was generated by calling
# randarray = rnd.randint(0, 5, train_valid.shape[0])
# Do NOT uncomment the above line of code. Instead, we are including
# the values you should use below.
randarray = np.array([2, 0, 1, 3, 0, 0, 0, 3, 2, 3, 1, 1, 2, 0, 4, 4, 0, 2, 1, 2, 2, 2,
                      4, 1, 3, 2, 0, 1, 2, 0, 3, 0, 3, 1, 3, 0, 4, 1, 4, 4, 0, 0, 1, 2,
                      4, 0, 0, 1, 1, 1, 2, 3, 4, 4, 3, 3, 0, 0, 0, 0, 2, 2, 3, 0, 0, 1,
                      4, 1, 4, 2, 2, 4, 4, 2, 0, 4, 0, 3, 2, 0, 4, 3, 1, 1, 0, 0, 0, 0,
                      1, 1, 4, 0, 3, 4, 2, 0, 0, 4, 4, 4, 4, 3, 3, 0, 0, 2, 2, 1, 3, 2,
                      4, 1, 2, 2, 3, 4, 1, 4, 3, 1, 1, 3, 0, 4, 4, 4, 0, 3, 3, 0, 4, 0,
                      0, 4, 3, 4, 1, 2, 2, 4, 4, 1, 2, 1, 1, 0, 4, 4, 4, 2, 0, 4, 2, 0,
                      4, 4, 1, 4, 0, 4, 0, 0, 1, 4, 3, 2, 4, 3, 1, 4, 1, 3, 4, 1, 0, 0,
                      4, 4, 2, 0, 4, 4, 4, 2, 3, 3, 4, 1, 0, 1, 2, 3, 1, 0, 1, 3, 4, 0,
                      0, 1, 2, 2, 2, 2, 4, 3, 1, 1, 4, 4, 1, 4, 2, 4, 0, 2, 4, 1, 3, 0,
                      4, 2, 3, 0, 4, 2, 3, 2, 2, 0, 2, 0, 2, 3, 2, 3, 4, 2, 4, 2, 2, 4,
                      3, 4, 0, 4, 4, 0, 1, 4, 2, 4, 2, 4, 0, 3, 4, 2, 1, 1, 3, 0, 1, 0,
                      3, 1, 3, 2, 4, 3, 1, 3, 0, 3, 0, 4, 2, 1, 2, 3, 2, 2, 4, 1, 4, 2,
                      1, 3, 1, 2, 2, 3, 1, 4, 2, 2, 4, 4, 1, 3, 2, 4, 1, 2, 4, 4, 0, 3,
                      1, 2, 1, 3, 3, 3, 2, 1, 3, 0, 2, 4, 2, 0, 3, 1, 0, 4, 2, 4, 1, 0,
                      4, 2, 2, 0, 1, 4, 3, 4, 0, 3, 2, 0, 2, 0])


train = train_valid[randarray[:]!=0]
valid = train_valid[randarray[:]==0]

print(train.shape)
print(valid.shape)

print('\nQuestion 1(h):')

# TODO
train_x = train[:,1:6] # TODO
train_t = train[:,6] # TODO
valid_x = valid[:,1:6] # TODO
valid_t = valid[:,6] # TODO
test_x = test[:,1:6] # TODO
test_t = test[:,6] # TODO

print(train_x[:2]) # TODO
print(train_t[:2]) # TODO
print(valid_x[:2]) # TODO
print(valid_t[:2]) # TODO
print(test_x[:2]) # TODO
print(test_t[:2]) # TODO



print('\nQuestion 1(i):')

data_mean = np.mean(data,0)
data_std = np.std(data,0)
x_mean = np.mean(train_x,0) # TODO
x_std = np.std(train_x,0) #TODO

print(x_mean)
print(x_std)


print('\nQuestion 1(j):')
print("Because the features have different ranges,The use of normalized data can improve the accuracy of validation")

# Include your response in your writeup
print('\nQuestion 1(k):')
print("Because training data use to train machine learning model to predict the outcome,thus the model is generated by the training data")
# Include your response in your writeup

print('\nQuestion 1(l):')

tmp_a = np.array([[1.4, 2.5, 3.0], [9.1, 3.4, 2.3]])
tmp_b = np.sum(tmp_a, axis=0)
print(tmp_a)
print(tmp_b)
print(tmp_a - tmp_b)
print('\n')
# Include your response in your writeup
print("tmp_b is the sum of each column, tmp_a-tmp_b is all arrays in temp_a minus tmp_b, in athematically is [[1.4 -10.5, 2.5-5.9, 3.0-5.3], [9.1-10.5, 3.4-5.9, 2.3-5.3]]")
print("Because tmp_b's dimension is 1, then when tmp_a-tmp_b, tmp_b will replicate itself meets the dimensions of tmp_a")

print('\nQuestion 1(m):')
zero_mean = train_x - np.mean(train_x,0)

unit_variance = train_x / np.std(train_x,0)


norm_train_x = (zero_mean)/np.std(train_x,0) # TODO


print(np.mean(norm_train_x,0))

print(norm_train_x[:2])

print('\nQuestion 1(n):')
import time
nonvec_before = time.time()

norm_train_x_loop = np.zeros_like(train_x)

for i in range(train_x.shape[0]):
    for j in range(train_x.shape[1]):
        norm_train_x_loop = (train_x[i, j] - x_mean[j]) / x_std[j]

nonvec_after = time.time()
print("Non-vectorized time: ", nonvec_after - nonvec_before)


vec_before = time.time()
# TODO: Add your code here
norm_train_x = (train_x - np.mean(train_x,0))/np.std(train_x,0)
vec_after = time.time()
print("Vectorized time: ", vec_after - vec_before)

# Include your response in your writeup
print("My code is about twice as fast as the one above")
print("Slower time:",(nonvec_after - nonvec_before)-(vec_after - vec_before ))

# Please leave these print statements, to help your TAs grade quickly.
print('\n\nQuestion 2')
print('----------')
print('\nQuestion 2(a):')

v = valid_x[0] # should be np.array([ 19.5    , 306.5947 ,   9.     ,  24.98034, 121.53951])
k = (train_x-v)**2
p = np.sum(k,1)

distances = np.sqrt(p) # TODO
print(distances[:10])
n = distances.argmin() # TODO

print(train_x[n])
print(train_t[n])


print('\nQuestion 2(b):')

smallest_3 = np.argpartition(distances,3)[:3]
print(smallest_3)
prediction = np.mean(train_t[smallest_3])
print(prediction)



print('\nQuestion 2(c):')

def unnorm_knn(v, k, features=train_x, labels=train_t):
    """
    Returns the k Nearest Neighbour prediction of housing prices for an input
    vector v.

    Parameters:
        v - The input vector to make predictions for
        k - The hyperparameter "k" in kNN
        features - The input features of the training data; a numpy array of shape [N, D]
                   (By default, `train_x` is used)
        labels - The target labels of the training data; a numpy array of shape [N]
                 (By default, `train_t` is used)
    """
    l = (train_x-v)**2
    p = np.sum(l,1)
    distances = np.sqrt(p)
    smallest_k = np.argpartition(distances,k)[:k]
    prediction = np.mean(train_t[smallest_k])
    return prediction
    

print(unnorm_knn(v=valid_x[1], k=5))

print(valid_t)
print('\nQuestion 2(d):')
def compute_mse(predict, data_x=valid_x, data_t=valid_t):
    """
    Returns the Mean Squared Error of a model across a dataset

    Parameters:
        predict - A Python *function* that takes an input vector and produces a
                  prediction for that vector.
        data_x - The input features of the data set to make predictions for
                 (By default, `valid_x` is used)
        data_t - The target labels of the dataset to make predictions for 
                 (By default, `train_t` is used)
    """

    errors = []
    for i in range(data_t.shape[0]):
        error = 0.5*(data_t[i]-predict(data_x[i]))**2 # TODO: replace "0.0" with the actual computed error
        errors.append(error) 
    return np.mean(errors)

def baseline(v):
    """
    Returns the average housing price given an input vector v.
    """
    return np.mean(train_t)

# compute and print the training and validation MSE
print(compute_mse(baseline, data_x=train_x, data_t=train_t))
print(compute_mse(baseline, data_x=valid_x, data_t=valid_t))

print('\nQuestion 2(e):')

train_mse = []
valid_mse = []
for k in range(1, 31):
    # create a temporary function `predict_fn` that computes the knn
    # prediction for the current value of the loop variable `k`
    def predict_fn(new_v):
        return unnorm_knn(new_v, k)

    # compute the training and validation MSE for this kNN model
    mse = compute_mse(predict_fn, data_x=train_x, data_t=train_t)
    train_mse.append(mse)
    mse = compute_mse(predict_fn, data_x=valid_x, data_t=valid_t)
    valid_mse.append(mse)


from matplotlib import pyplot as plt
plt.plot(range(1, 31), train_mse)
plt.plot(range(1, 31), valid_mse)
plt.xlabel("k")
plt.ylabel("MSE")
plt.title("Unnormalized kNN")
plt.legend(["Training", "Validation"])
plt.show()

# Include your response in your writeup


print('\nQuestion 2(f):')

def norm_knn(v, k, features=norm_train_x, means=x_mean, stds=x_std, labels=train_t):
    """
    Returns the k Nearest Neighbour prediction of housing prices for an input
    vector v.

    Parameters:
        v - The input vector to make predictions for
        k - The hyperparameter "k" in kNN
        features - The normalized input features of the training data
                   (By default, `norm_train_x` is used)
        means - The means over the training data (By default, `x_mean` is used)
        stds - The standard deviations of the training data (By default, `x_std` is used)
        labels - The target labels of the training data; a numpy array of shape [N]
                 (By default, `train_t` is used)
    """
    l = (norm_train_x-v)**2
    p = np.sum(l,1)
    distances = np.sqrt(p)
    smallest_k = np.argpartition(distances,k)[:k]
    prediction = np.mean(train_t[smallest_k])
    return prediction
    

train_mse = []
valid_mse = []
for k in range(1, 31):
    # create a temporary function `predict_fn` that computes the knn
    # prediction for the current value of the loop variable `k`
    def predict_fn(new_v):
        return norm_knn(new_v, k)

    # compute the training and validation MSE for this kNN model
    mse = compute_mse(predict_fn, data_x=train_x, data_t=train_t)
    train_mse.append(mse)
    mse = compute_mse(predict_fn, data_x=valid_x, data_t=valid_t)
    valid_mse.append(mse)


from matplotlib import pyplot as plt
plt.plot(range(1, 31), train_mse)
plt.plot(range(1, 31), valid_mse)
plt.xlabel("k")
plt.ylabel("MSE")
plt.title("Normalized kNN")
plt.legend(["Training", "Validation"])
plt.show()

# Include your response in your writeup

# Include your response in your writeup

# Include your response in your writeup

# Include your response in your writeup

# Please leave these print statements, to help your TAs grade quickly.
print('\n\nQuestion 3')
print('----------')

train_d = train_x[:, 0] # house age

# Plot this feature against the target (house price)
plt.scatter(train_d, train_t)
plt.xlabel("House Age")
plt.ylabel("House Price")
plt.title("House Age vs. Price")
plt.show()

print('\nQuestion 3(a):')

X = np.c_[np.ones((len(train_d),1)),train_d]

X_1 = np.linalg.inv(np.dot(X.T,X))

linear_coef = np.dot(X_1, np.dot(X.T,train_t))# TODO


print(linear_coef)

print('\nQuestion 3(b):')

def pred_linear(v, coef=linear_coef):
    """
    Returns the linear regression predictions of house prices, given
    a vector consisting of the ages of several houses that we would
    like to make predictions for.

    Parameters:
        v - A vector of house ages
        coef - The linear regression coefficient
    """
    
    
    
    return np.dot(np.c_[np.ones((len(v),1)),v],coef) # TODO Replace this with the actual solution

def plot_prediction(predict, title):
    """
    Display a plot that superimposes the model predictions on a scatter
    plot of the training data (train_d, train_t)

    Parameters:
        predict - A Python *function* that takes an input vector and produces a
                  prediction for that vector.
        title - A title to display on the figure.
    """
    # start with a scatter plot
    plt.scatter(train_d, train_t)

    # create several "house age" values to make predictions for
    min_age = np.min(train_d)
    max_age = np.max(train_d)
    v = np.arange(min_age, max_age, 0.1)

    # make predictions for those values
    y = predict(v)

    # plot the result
    plt.plot(v, y)
    plt.title(title)
    plt.xlabel("House Age")
    plt.ylabel("House Price")
    plt.show()

plot_prediction(pred_linear, title="Linear Regression (no feature expansion)")

print('\nQuestion 3(c):')

print(np.shape(valid_t))
def compute_mse_vectorized(predict, data_x=valid_x, data_t=valid_t):
    """
    Returns the Mean Squared Error of a model across a dataset

    Parameters:
        predict - A Python *function* that takes a vector of house ages, 
                  and produces a vector of house price predictions
        data_x - The input features of the data set to make predictions for
                 (By default, `valid_x` is used)
        data_t - The target labels of the dataset to make predictions for 
                 (By default, `train_t` is used)
    """
    
    
    
    v = data_x[:, 0] # house age
    V_1 = data_t-predict
    v_2 = 0.5*(V_1)**2

    return np.mean(v_2) # TODO


print('\nQuestion 3(d):')
X = np.c_[np.ones((len(train_d),1)),train_d]
X_1 = np.c_[X,train_d**2]

X_2 = np.linalg.inv(np.dot(X_1.T,X_1))


quad_coef = np.dot(X_2, np.dot(X_1.T,train_t)) # TODO

print(quad_coef)
print('\nQuestion 3(e):')

def pred_quad(v, coef=quad_coef):
    """
    Returns the degree 2 polynomial regression predictions of
    house prices, given a vector consisting of the ages of several houses
    that we would like to make predictions for.

    Parameters:
        v - A vector of house ages
        coef - The linear regression coefficient
    """
    X = np.c_[np.ones((len(v),1)),v]
    X_1 = np.c_[X,v**2]
    #X_2 = np.linalg.inv(np.dot(X_1.T,X_1))
    return  np.dot(X_1, coef) # TODO replace this line

plot_prediction(pred_quad, title="Polynomial Regression (M=2)")

print('\nQuestion 3(f):')

print(np.shape(pred_quad(train_d,quad_coef)))
print(np.shape(pred_quad(valid_x[:,0],quad_coef)))

train_mse_q = compute_mse_vectorized(pred_quad(train_d,quad_coef), data_x=train_x, data_t=train_t)

valid_mse_q = compute_mse_vectorized(pred_quad(valid_x[:,0],quad_coef), data_x=valid_x, data_t=valid_t)

print(train_mse_q)
print(valid_mse_q)

# TODO

print('\nQuestion 3(g):')


train_mse_r = []
valid_mse_r = []
X = np.ones((len(train_d),1)) # TODO
X_1 = np.ones((len(valid_x[:,0]),1))

for M in range(0, 11):
    if M > 0 :
        X = np.c_[X,train_d**(M)]
        X_1 = np.c_[X_1,valid_x[:,0]**(M)]
        
    p_1 = np.linalg.inv(np.dot(X.T,X))
    p_2 = np.linalg.inv(np.dot(X_1.T,X_1))
    M_coef = np.dot(p_1, np.dot(X.T,train_t))
    V_coef = np.dot(p_2, np.dot(X_1.T,valid_t))
    pre_M_t = np.dot(X, M_coef)
    pre_M_v = np.dot(X_1, V_coef)
    
    train_mse_t = compute_mse_vectorized(pre_M_t, data_x=train_x, data_t=train_t)
    valid_mse_t = compute_mse_vectorized(pre_M_v, data_x=valid_x, data_t=valid_t)
    
    train_mse_r.append(train_mse_t) # TODO replace this
    valid_mse_r.append(valid_mse_t) # TODO replace this 
    print(M_coef)

print(train_mse_r)
print(valid_mse_r)

print('\nQuestion 3(h):')
# Include your response in your writeup


print('\nQuestion 3(i):')
plt.plot(range(0, 11), train_mse_r)
plt.plot(range(0, 11), valid_mse_r)
plt.xlabel("Polynomial Degree")
plt.ylabel("MSE")
plt.title("Polynomial Regression")
plt.legend(["Training", "Validation"])
plt.show()

# Include your response in your writeup
print('\nQuestion 3(j):')

X = np.c_[np.ones((len(train_d),1)),train_d**(1),train_d**(2)]

for M in range(3, 11):
  
    X = np.c_[X,train_d**(M)]
        
    p_1 = np.linalg.inv(np.dot(X.T,X))
    M_coef = np.dot(p_1, np.dot(X.T,train_t))
    
    pre_M_t = np.dot(X, M_coef)
    
    
    def pred(v,coef = M_coef,k = M):
        if k == 3:
            X = np.c_[np.ones((len(v),1)),v**(1),v**(2),v**(3)]
        if k == 4:
            X = np.c_[np.ones((len(v),1)),v**(1),v**(2),v**(3),v**(4)]
        if k == 5:
            X = np.c_[np.ones((len(v),1)),v**(1),v**(2),v**(3),v**(4),v**(5)]
        if k == 6:
            X = np.c_[np.ones((len(v),1)),v**(1),v**(2),v**(3),v**(4),v**(5),v**(6)]
        if k == 7:
            X = np.c_[np.ones((len(v),1)),v**(1),v**(2),v**(3),v**(4),v**(5),v**(6),v**(7)]
        if k == 8:
            X = np.c_[np.ones((len(v),1)),v**(1),v**(2),v**(3),v**(4),v**(5),v**(6),v**(7),v**(8)]
        if k == 9:
            X = np.c_[np.ones((len(v),1)),v**(1),v**(2),v**(3),v**(4),v**(5),v**(6),v**(7),v**(8),v**(9)]      
        if k == 10:
            X = np.c_[np.ones((len(v),1)),v**(1),v**(2),v**(3),v**(4),v**(5),v**(6),v**(7),v**(8),v**(9),v**(10)] 
        if k == 11:
            X = np.c_[np.ones((len(v),1)),v**(1),v**(2),v**(3),v**(4),v**(5),v**(6),v**(7),v**(8),v**(9),v**(10),v**(11)]
        return np.dot(X, coef)
    
    plot_prediction(pred, title="Polynomial Regression (M=%d)" % M)


# Include your response in your writeup

# Include your response in your writeup

# Include your response in your writeup

# Include your response in your writeup

# Include your response in your writeup

# Include your response in your writeup

# Include your response in your writeup

# Please leave these print statements, to help your TAs grade quickly.
print('\n\nQuestion 4')
print('----------')
print('\nQuestion 4(e):')

def grad(weight, X, t):
    '''
    Return gradient of each weight evaluated at the current value

    Parameters:
        `weight` - a current "guess" of what our weights should be,
                   a numpy array of shape (D)
        `X` - matrix of shape (N,D) of input features
        `t` - target y values of shape (N)

    '''
    return None

# Please leave this print statement for grading:
print(grad(np.array([1]), np.array([[1], [1]]), np.array([2, 2])))

# Include your response in your writeup

print('\nQuestion 4(g):')

def solve_via_gradient_descent(M, alpha=0.0025, niter=10000):
    '''
    Given `M` - maximum degree of the polynomial regression model
          `alpha` - the learning rate
          `niter` - the number of iterations of gradient descent to run
    Solves for linear regression weights.
    Return weights after `niter` iterations.
    '''
    # initialize all the weights to zeros
    w = np.zeros([M + 1])

    # construct the design matrix
    for i in range(niter):
        w = w # TODO
    return w

print(solve_via_gradient_descent(M=1, alpha=0.0025, niter=10000))

# Include your response in your writeup

print('\nQuestion 4(i):')
print(solve_via_gradient_descent(M=1, alpha=0.01, niter=50))

# Include your response in your writeup

# Include your response in your writeup





# Include your response in your writeup

# Include your response in your writeup

# print(...) # TODO

# Include your response in your writeup
